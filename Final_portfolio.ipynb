{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6294a7",
   "metadata": {},
   "source": [
    "# Final assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26427d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random as rdm\n",
    "wd = r\"C:/Documentos/University/Econometrics/Thesis/\"\n",
    "#wd = r\"C:/Users/Data Science/Downloads/Thesis/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c777e84",
   "metadata": {},
   "source": [
    "# Simulation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09238734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    def __init__(self, size, start_age, max_age, num_simulations, value_upfront, seed):\n",
    "        \"\"\"\n",
    "        Initialize the population simulator with multiple populations\n",
    "        \n",
    "        Args:\n",
    "            size (int): Number of individuals per population (n in the paper)\n",
    "            start_age (int): Starting age of the population (x in the paper, default Dutch retirement age is 67)\n",
    "            max_age (int): Maximum age to simulate\n",
    "            num_simulations (int): Number of populations to simulate\n",
    "            value_upfront (float): Value each member pays to join the GSA (v_N_i(0) in the paper)\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        # Initialize the Population parameters\n",
    "        self.size = size  # n in the paper\n",
    "        self.start_age = start_age  # x in the paper\n",
    "        self.max_age = max_age\n",
    "        self.num_simulations = num_simulations\n",
    "        \n",
    "        self.timeline = self.max_age - self.start_age\n",
    "        # L_x+t in the paper (equation 3) - tracks surviving members\n",
    "        self.alive = np.zeros((self.num_simulations, self.size, self.timeline), dtype=int)\n",
    "        \n",
    "        # Initialize portfolio values\n",
    "        self.value_upfront = value_upfront  # v_N_i(0) in the paper\n",
    "        # v_N_i(t) in the paper - nominal account value for each member\n",
    "        self.v_N_i = self.alive.copy()\n",
    "        # V_N(t) in the paper - total nominal portfolio value\n",
    "        self.V_N = self.alive[:,0].copy()\n",
    "        # B_i(t) in the paper (equation 7) - nominal cashflows\n",
    "        self.cashflows = self.alive.copy()\n",
    "        \n",
    "        # Initialize random generator\n",
    "        self.rng = rdm.default_rng(seed)\n",
    "        \n",
    "        # Initialize survival probabilities array\n",
    "        self.survival_probabilities = None\n",
    "        \n",
    "        # Initialize variables for real values\n",
    "        self.v_R_i = None  # Real account value for each member\n",
    "        self.V_R = None    # Real total portfolio value\n",
    "        self.B_R_i = None  # Real cashflows (equation 20)\n",
    "        \n",
    "        # Stability tolerance parameters (section 1.6)\n",
    "        self.epsilon_1 = 0.1  # Nominal lower tolerance\n",
    "        self.epsilon_2 = 0.1  # Nominal upper tolerance\n",
    "        self.epsilon_R_1 = 0.15  # Real lower tolerance\n",
    "        self.epsilon_R_2 = 0.15  # Real upper tolerance\n",
    "        self.epsilon_P_1 = 0.1  # Cumulative real lower tolerance\n",
    "        self.epsilon_P_2 = 0.1  # Cumulative real upper tolerance\n",
    "        \n",
    "    def set_stability_tolerances(self, epsilon_1, epsilon_2, epsilon_R_1, epsilon_R_2, epsilon_P_1, epsilon_P_2):\n",
    "        \"\"\"\n",
    "        Set the tolerance levels for stability checks as defined in section 1.6 of the paper.\n",
    "        \n",
    "        Args:\n",
    "            epsilon_1 (float): Nominal lower tolerance (equation 21)\n",
    "            epsilon_2 (float): Nominal upper tolerance (equation 21)\n",
    "            epsilon_R_1 (float): Real lower tolerance (equation 22)\n",
    "            epsilon_R_2 (float): Real upper tolerance (equation 22)\n",
    "            epsilon_P_1 (float): Cumulative real lower tolerance (equation 23)\n",
    "            epsilon_P_2 (float): Cumulative real upper tolerance (equation 23)\n",
    "        \"\"\"\n",
    "        self.epsilon_1 = epsilon_1\n",
    "        self.epsilon_2 = epsilon_2\n",
    "        self.epsilon_R_1 = epsilon_R_1\n",
    "        self.epsilon_R_2 = epsilon_R_2\n",
    "        self.epsilon_P_1 = epsilon_P_1\n",
    "        self.epsilon_P_2 = epsilon_P_2\n",
    "        \n",
    "    def set_survival_probabilities(self, survival_probs):\n",
    "        \"\"\"\n",
    "        Set the age-based survival probabilities (p_x+t in the paper, equation 4)\n",
    "        \n",
    "        Args:\n",
    "            survival_probs (np.ndarray): Array of shape (n, 2) where each row contains \n",
    "                [age, probability] pairs\n",
    "        \"\"\"\n",
    "        # Check if the provided probabilities start at start_age\n",
    "        if survival_probs[0, 0] != self.start_age:\n",
    "            # Find the index where age >= start_age\n",
    "            start_idx = np.searchsorted(survival_probs[:, 0], self.start_age)\n",
    "            survival_probs = survival_probs[start_idx:]\n",
    "        \n",
    "        # Ensure there are enough probabilities for the timeline-1 transitions\n",
    "        if len(survival_probs) < self.timeline - 1:\n",
    "            raise ValueError(\"Insufficient survival probabilities for the simulation timeline.\")\n",
    "        \n",
    "        # Convert survival probabilities to float64\n",
    "        self.survival_probabilities = survival_probs.astype(np.float64)\n",
    "        \n",
    "    def run_mortality_simulation(self):\n",
    "        \"\"\"\n",
    "        Run the population simulation using vectorized binomial sampling and cumulative product.\n",
    "        Implements equation (5) from the paper: L_x+t ~ Bin(L_x+t-1, p_x+t-1)\n",
    "        \"\"\"\n",
    "        if self.survival_probabilities is None:\n",
    "            raise ValueError(\"Survival probabilities have not been set.\")\n",
    "        \n",
    "        # Extract relevant survival probabilities (timeline-1 entries)\n",
    "        relevant_probs = self.survival_probabilities[:self.timeline-1, 1]\n",
    "        \n",
    "        # Generate all survival trials upfront using binomial distribution (equation 5)\n",
    "        # Shape: num_simulations x size x timeline-1\n",
    "        trials = self.rng.binomial(n=1, p=relevant_probs, size=(self.num_simulations, self.size, self.timeline-1))\n",
    "        \n",
    "        # Initialize the alive array with ones at t=0 (all members start alive)\n",
    "        self.alive[..., 0] = 1\n",
    "        \n",
    "        # Compute cumulative product of trials across the timeline dimension\n",
    "        # This ensures individuals remain dead after their first death\n",
    "        cumulative_trials = np.ones((self.num_simulations, self.size, self.timeline), dtype=int)\n",
    "        cumulative_trials[..., 1:] = trials\n",
    "        self.alive = np.cumprod(cumulative_trials, axis=2)\n",
    "    \n",
    "    def calculate_cashflows_and_portfolio(self, interest_rates, annuity_discount):\n",
    "        \"\"\"\n",
    "        Calculate cash flows and update portfolio values according to the paper's model.\n",
    "        \n",
    "        Args:\n",
    "            interest_rates (np.ndarray): R_t in the paper (equation 11) - 1D array of interest rates\n",
    "            annuity_discount (float): discount rate r for annuity calculation (equation 8-9)\n",
    "        \"\"\"\n",
    "        # Calculate annuity factors (ä_x+t in equation 8)\n",
    "        annuity_factors = self.calculate_apv(annuity_discount)\n",
    "        \n",
    "        # Ensure annuity factors are positive and non-zero\n",
    "        annuity_factors = np.maximum(annuity_factors, 1e-10)\n",
    "        \n",
    "        timeline = self.timeline\n",
    "        num_sim = self.num_simulations\n",
    "        size = self.size\n",
    "\n",
    "        # Initialize portfolio values at t=0 (equation: v_N_i(0) = value_upfront)\n",
    "        self.v_N_i[..., 0] = self.alive[..., 0] * self.value_upfront\n",
    "\n",
    "        for t in range(timeline - 1):\n",
    "            # Current portfolio values for each member at time t\n",
    "            current_portfolio = self.v_N_i[..., t]\n",
    "            \n",
    "            # Ensure positive portfolio values (avoid negative balances)\n",
    "            current_portfolio = np.maximum(current_portfolio, 0)\n",
    "\n",
    "            # Calculate cashflows B_i(t) using equation (7)\n",
    "            # B_i(t) = I{T_i > t} * v_N_i(t) / ä_x+t\n",
    "            B_t = (current_portfolio / annuity_factors[t]) * self.alive[..., t]\n",
    "            \n",
    "            # Ensure cashflows do not exceed the portfolio value and are non-negative\n",
    "            B_t = np.minimum(B_t, current_portfolio)\n",
    "            B_t = np.maximum(B_t, 0)\n",
    "            self.cashflows[..., t] = B_t\n",
    "\n",
    "            # Subtract cashflow and apply interest rate to the remaining balance\n",
    "            remaining_after_cashflow = current_portfolio - B_t\n",
    "            remaining_after_cashflow = np.maximum(remaining_after_cashflow, 0)  # Prevent negative values\n",
    "            \n",
    "            R_t = interest_rates[t]\n",
    "            temp = remaining_after_cashflow * (1 + R_t)\n",
    "\n",
    "            # Determine deceased members between t and t+1\n",
    "            deceased_mask = (self.alive[..., t] == 1) & (self.alive[..., t+1] == 0)\n",
    "            \n",
    "            # Calculate total remaining funds from deceased members (after cashflow and return)\n",
    "            total_deceased = np.sum(temp * deceased_mask, axis=1, keepdims=True)\n",
    "            \n",
    "            # Count survivors (denominator of equation 13)\n",
    "            survivors = np.sum(self.alive[..., t+1], axis=1, keepdims=True)\n",
    "            survivors_safe = np.maximum(survivors, 1e-10)  # Avoid division by zero\n",
    "\n",
    "            # Compute longevity credit (λ(t+1) in equation 13)\n",
    "            longevity_credit = total_deceased / survivors_safe\n",
    "            longevity_credit = np.maximum(longevity_credit, 0)  # Ensure non-negative\n",
    "\n",
    "            # Update portfolio values for survivors: add longevity credit\n",
    "            self.v_N_i[..., t+1] = (temp + longevity_credit * self.alive[..., t+1]) * self.alive[..., t+1]\n",
    "\n",
    "        # Set final period cashflows (distribute remaining portfolio)\n",
    "        t = timeline - 1\n",
    "        current_portfolio = self.v_N_i[..., t]\n",
    "        current_portfolio = np.maximum(current_portfolio, 0)\n",
    "        self.cashflows[..., t] = current_portfolio * self.alive[..., t]\n",
    "\n",
    "        # Update total portfolio (V_N(t) from equation 10)\n",
    "        for t in range(timeline):\n",
    "            self.V_N[:, t] = np.sum(self.v_N_i[:, :, t], axis=1)\n",
    "    \n",
    "    def real_cashflows(self, inflation_rates):\n",
    "        \"\"\"\n",
    "        Convert nominal values to real terms using inflation rates (equation 1 and 20).\n",
    "        \n",
    "        Args:\n",
    "            inflation_rates (np.ndarray): 1D array of I_t = CPI_t/CPI_0 for each t (equation 2).\n",
    "        \"\"\"\n",
    "        # Reshape for broadcasting\n",
    "        inflation_3d = inflation_rates[np.newaxis, np.newaxis, :]\n",
    "        inflation_2d = inflation_rates[np.newaxis, :]\n",
    "\n",
    "        # Equation (1): V_R(t) = V_N(t) / I_t\n",
    "        self.v_R_i = self.v_N_i / inflation_3d  # Real account value for each member\n",
    "        self.V_R = self.V_N / inflation_2d      # Real total portfolio value\n",
    "        \n",
    "        # Equation (20): B_R_i(t) = B_i(t) / I_t\n",
    "        self.B_R_i = self.cashflows / inflation_3d  # Real cashflows\n",
    "\n",
    "    def check_stability(self, max_age=None):\n",
    "        \"\"\"\n",
    "        Check what percentage of simulations meet stability requirements defined in equations (21), (22), and (23)\n",
    "        up to a specified age.\n",
    "        \n",
    "        Args:\n",
    "            max_age (int, optional): Maximum age until which stability is checked. \n",
    "                                    If None, checks until the end of simulation.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (nominal_stable_pct, real_stable_pct, cumulative_real_stable_pct)\n",
    "                - nominal_stable_pct: Percentage of simulations where nominal cashflows remain within tolerance\n",
    "                - real_stable_pct: Percentage of simulations where real cashflows remain within tolerance\n",
    "                - cumulative_real_stable_pct: Percentage of simulations where cumulative real cashflows remain within tolerance\n",
    "        \"\"\"\n",
    "        if self.B_R_i is None:\n",
    "            raise ValueError(\"Real cashflows have not been calculated. Run real_cashflows first.\")\n",
    "        \n",
    "        # Convert max_age to corresponding time index if provided\n",
    "        if max_age is not None:\n",
    "            if max_age < self.start_age:\n",
    "                raise ValueError(f\"max_age must be at least {self.start_age}\")\n",
    "            # Calculate the timeline index corresponding to max_age\n",
    "            t_max = min(max_age - self.start_age + 1, self.timeline)\n",
    "        else:\n",
    "            t_max = self.timeline\n",
    "        \n",
    "        # Get initial cashflows (t=0) for each simulation and member\n",
    "        initial_cashflows = self.cashflows[..., 0]\n",
    "        \n",
    "        # Calculate bounds for stability checks\n",
    "        # Equation (21): B_i(t) ∈ [(1-ε_1)B_i(0), (1+ε_2)B_i(0)]\n",
    "        lower_bound_nominal = (1 - self.epsilon_1) * initial_cashflows\n",
    "        upper_bound_nominal = (1 + self.epsilon_2) * initial_cashflows\n",
    "        \n",
    "        # Equation (22): B_R_i(t) ∈ [(1-ε_R_1)B_i(0), (1+ε_R_2)B_i(0)]\n",
    "        lower_bound_real = (1 - self.epsilon_R_1) * initial_cashflows\n",
    "        upper_bound_real = (1 + self.epsilon_R_2) * initial_cashflows\n",
    "        \n",
    "        # Check stability only up to t_max\n",
    "        nominal_stable = np.ones((self.num_simulations, self.size), dtype=bool)\n",
    "        real_stable = np.ones((self.num_simulations, self.size), dtype=bool)\n",
    "        \n",
    "        # For each time period up to t_max, check if cashflows remain within bounds\n",
    "        for t in range(t_max):\n",
    "            # For nominal cashflows: check if within bounds AND the person is alive\n",
    "            current_nominal = self.cashflows[..., t]\n",
    "            alive_mask = self.alive[..., t] == 1\n",
    "            \n",
    "            # Only consider stability violations for living individuals\n",
    "            nominal_in_bounds = ((current_nominal >= lower_bound_nominal) & \n",
    "                                (current_nominal <= upper_bound_nominal))\n",
    "            \n",
    "            # Consider criteria met for deceased individuals (avoid counting them in violations)\n",
    "            nominal_valid = nominal_in_bounds | ~alive_mask\n",
    "            \n",
    "            # If ANY time period violates stability, mark the simulation-member pair as unstable\n",
    "            nominal_stable = nominal_stable & nominal_valid\n",
    "            \n",
    "            # Same process for real cashflows\n",
    "            current_real = self.B_R_i[..., t]\n",
    "            real_in_bounds = ((current_real >= lower_bound_real) & \n",
    "                            (current_real <= upper_bound_real))\n",
    "            real_valid = real_in_bounds | ~alive_mask\n",
    "            real_stable = real_stable & real_valid\n",
    "        \n",
    "        # Calculate percentage of simulation-members that maintained stability\n",
    "        # First, filter to only consider individuals who were alive at t=0\n",
    "        initially_alive = self.alive[..., 0] == 1\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_initially_alive = np.sum(initially_alive)\n",
    "        nominal_stable_count = np.sum(nominal_stable & initially_alive)\n",
    "        real_stable_count = np.sum(real_stable & initially_alive)\n",
    "        \n",
    "        nominal_stable_pct = (nominal_stable_count / total_initially_alive) * 100 if total_initially_alive > 0 else 0\n",
    "        real_stable_pct = (real_stable_count / total_initially_alive) * 100 if total_initially_alive > 0 else 0\n",
    "        \n",
    "        # For cumulative stability check (equation 23)\n",
    "        # Only consider cashflows up to t_max\n",
    "        cum_real_cashflows = np.sum(self.B_R_i[..., :t_max], axis=2)\n",
    "        initial_value = self.value_upfront\n",
    "        lower_bound_cum = (1 - self.epsilon_P_1) * initial_value\n",
    "        upper_bound_cum = (1 + self.epsilon_P_2) * initial_value\n",
    "        \n",
    "        # Check if cumulative cashflows are within bounds for initially alive members\n",
    "        cumulative_real_stable = ((cum_real_cashflows >= lower_bound_cum) & \n",
    "                                (cum_real_cashflows <= upper_bound_cum))\n",
    "        \n",
    "        cumulative_real_stable_count = np.sum(cumulative_real_stable & initially_alive)\n",
    "        cumulative_real_stable_pct = (cumulative_real_stable_count / total_initially_alive) * 100 if total_initially_alive > 0 else 0\n",
    "        \n",
    "        return nominal_stable_pct, real_stable_pct, cumulative_real_stable_pct\n",
    "    \n",
    "    def get_live_people(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate number of live individuals at each time period for all simulations.\n",
    "        Returns L_x+t from equation (3) summed over all members.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Shape (timeline, num_simulations)\n",
    "        \"\"\"\n",
    "        return self.alive.sum(axis=1).T\n",
    "    \n",
    "    def get_empirical_survival_probability(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate empirical survival probabilities (ˆp_x+t in equation 6) for each simulation at every time t.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Shape (timeline, num_simulations)\n",
    "        \"\"\"\n",
    "        live = self.get_live_people()  # (timeline, simulations)\n",
    "        empirical_p = np.zeros_like(live, dtype=np.float64)\n",
    "        \n",
    "        # Compute p(t) = L(t+1)/L(t) with division-by-zero protection (equation 6)\n",
    "        np.divide(live[1:], live[:-1], out=empirical_p[:-1], where=live[:-1] != 0)\n",
    "        return empirical_p\n",
    "    \n",
    "    def calculate_apv(self, discount_rate: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate the Actuarial Present Value (ä_x+t in equation 8).\n",
    "        \n",
    "        Args:\n",
    "            discount_rate (float): Discount rate r for APV calculation\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Annuity factors for each time period\n",
    "        \"\"\"\n",
    "        if self.survival_probabilities is None:\n",
    "            raise ValueError(\"Survival probabilities not set.\")\n",
    "        \n",
    "        # Extract survival probabilities p_x+t\n",
    "        p = self.survival_probabilities[:self.timeline-1, 1]\n",
    "        timeline = self.timeline\n",
    "        annuity_factors = np.zeros(timeline)\n",
    "        \n",
    "        # Calculate ä_x+t according to equation (8)\n",
    "        for t in range(timeline):\n",
    "            max_j = timeline - t\n",
    "            # Calculate j_p_x+t (probability of surviving j more years at age x+t)\n",
    "            jp = np.ones(max_j)\n",
    "            for j in range(1, max_j):\n",
    "                if t + j - 1 < len(p):\n",
    "                    jp[j] = jp[j-1] * p[t + j - 1]\n",
    "                else:\n",
    "                    jp[j] = 0.0\n",
    "                    \n",
    "            # Calculate discount factors 1/(1+r)^j\n",
    "            discount_factors = 1 / (1 + discount_rate) ** np.arange(max_j)\n",
    "            \n",
    "            # Calculate annuity factor as sum of discounted survival probabilities\n",
    "            annuity_factors[t] = np.sum(jp * discount_factors)\n",
    "            \n",
    "        return annuity_factors\n",
    "        \n",
    "\n",
    "    def relevant_metrics(self):\n",
    "        \"\"\"\n",
    "        Compute relevant metrics across simulations and return two DataFrames.\n",
    "        Means are calculated only over living members using vectorized operations.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: \n",
    "                - pd.DataFrame: Metrics over time with mean and variance of payments, portfolios, and people alive.\n",
    "                - pd.DataFrame: Aggregated sum of cashflows with mean, variance, and original value upfront.\n",
    "        \"\"\"\n",
    "        timeline = self.timeline\n",
    "        index = pd.Index([self.start_age + t for t in range(timeline)], name='Age')\n",
    "        \n",
    "        # Precompute live_people array (timeline x num_simulations)\n",
    "        live_people = self.get_live_people()  # Shape (timeline, num_simulations)\n",
    "        \n",
    "        # Initialize lists to collect data for the first DataFrame\n",
    "        metrics_data = []\n",
    "        for t in range(timeline):\n",
    "            # Get number of alive people for current time t across simulations\n",
    "            alive_t = live_people[t, :]\n",
    "            mean_alive = np.mean(alive_t)\n",
    "            var_alive = np.var(alive_t, ddof=1) if len(alive_t) > 1 else 0\n",
    "            \n",
    "            # Get alive mask for current time t (shape: num_simulations x size)\n",
    "            alive_mask = self.alive[:, :, t]  # 1 for alive, 0 for dead\n",
    "            \n",
    "            # Get data for current time t\n",
    "            cashflows_t = self.cashflows[:, :, t]\n",
    "            cashflows_real_t = self.B_R_i[:, :, t] if self.B_R_i is not None else None\n",
    "            portfolio_personal_t = self.v_N_i[:, :, t]\n",
    "            portfolio_total_t = self.V_N[:, t]\n",
    "            \n",
    "            # Get real portfolio data if available\n",
    "            portfolio_personal_real_t = self.v_R_i[:, :, t] if self.v_R_i is not None else None\n",
    "            portfolio_total_real_t = self.V_R[:, t] if self.V_R is not None else None\n",
    "            \n",
    "            # Calculate means for each simulation, only considering alive members\n",
    "            # For each simulation, sum the values for alive members and divide by count of alive members\n",
    "            \n",
    "            # Sum of cashflows for alive members in each simulation\n",
    "            cashflow_sums = np.sum(cashflows_t * alive_mask, axis=1)\n",
    "            # Count of alive members in each simulation\n",
    "            alive_counts = np.sum(alive_mask, axis=1)\n",
    "            # Safe division (avoid divide by zero)\n",
    "            alive_counts_safe = np.maximum(alive_counts, 1)\n",
    "            # Mean cashflow per alive member in each simulation\n",
    "            sim_means_nom = cashflow_sums / alive_counts_safe\n",
    "            \n",
    "            # Mean and variance across simulations\n",
    "            mean_payment_nom = np.mean(sim_means_nom)\n",
    "            var_payment_nom = np.var(sim_means_nom, ddof=1) if len(sim_means_nom) > 1 else 0\n",
    "            \n",
    "            # Same approach for real cashflows if available\n",
    "            if cashflows_real_t is not None:\n",
    "                cashflow_real_sums = np.sum(cashflows_real_t * alive_mask, axis=1)\n",
    "                sim_means_real = cashflow_real_sums / alive_counts_safe\n",
    "                mean_payment_real = np.mean(sim_means_real)\n",
    "                var_payment_real = np.var(sim_means_real, ddof=1) if len(sim_means_real) > 1 else 0\n",
    "            else:\n",
    "                mean_payment_real = None\n",
    "                var_payment_real = None\n",
    "            \n",
    "            # Same approach for personal portfolio (nominal)\n",
    "            portfolio_sums = np.sum(portfolio_personal_t * alive_mask, axis=1)\n",
    "            sim_means_personal = portfolio_sums / alive_counts_safe\n",
    "            mean_port_personal = np.mean(sim_means_personal)\n",
    "            var_port_personal = np.var(sim_means_personal, ddof=1) if len(sim_means_personal) > 1 else 0\n",
    "            \n",
    "            # Same approach for personal portfolio (real) if available\n",
    "            if portfolio_personal_real_t is not None:\n",
    "                portfolio_real_sums = np.sum(portfolio_personal_real_t * alive_mask, axis=1)\n",
    "                sim_means_personal_real = portfolio_real_sums / alive_counts_safe\n",
    "                mean_port_personal_real = np.mean(sim_means_personal_real)\n",
    "                var_port_personal_real = np.var(sim_means_personal_real, ddof=1) if len(sim_means_personal_real) > 1 else 0\n",
    "            else:\n",
    "                mean_port_personal_real = None\n",
    "                var_port_personal_real = None\n",
    "            \n",
    "            # Total portfolio is already summed over all members (nominal)\n",
    "            mean_port_total = np.mean(portfolio_total_t)\n",
    "            var_port_total = np.var(portfolio_total_t, ddof=1) if len(portfolio_total_t) > 1 else 0\n",
    "            \n",
    "            # Total portfolio (real) if available\n",
    "            if portfolio_total_real_t is not None:\n",
    "                mean_port_total_real = np.mean(portfolio_total_real_t)\n",
    "                var_port_total_real = np.var(portfolio_total_real_t, ddof=1) if len(portfolio_total_real_t) > 1 else 0\n",
    "            else:\n",
    "                mean_port_total_real = None\n",
    "                var_port_total_real = None\n",
    "            \n",
    "            # Append the row data\n",
    "            metrics_data.append([\n",
    "                mean_payment_nom, mean_payment_real,\n",
    "                var_payment_nom, var_payment_real,\n",
    "                mean_port_personal, mean_port_personal_real,\n",
    "                var_port_personal, var_port_personal_real,\n",
    "                mean_port_total, mean_port_total_real,\n",
    "                var_port_total, var_port_total_real,\n",
    "                mean_alive, var_alive\n",
    "            ])\n",
    "        \n",
    "        # Create the first DataFrame\n",
    "        columns_df1 = [\n",
    "            'mean_payment_nominal', 'mean_payment_real',\n",
    "            'var_payment_nominal', 'var_payment_real',\n",
    "            'mean_portfolio_personal_nominal', 'mean_portfolio_personal_real',\n",
    "            'var_portfolio_personal_nominal', 'var_portfolio_personal_real',\n",
    "            'mean_portfolio_total_nominal', 'mean_portfolio_total_real',\n",
    "            'var_portfolio_total_nominal', 'var_portfolio_total_real',\n",
    "            'mean_people_alive', 'var_people_alive'\n",
    "        ]\n",
    "        df1 = pd.DataFrame(metrics_data, index=index, columns=columns_df1)\n",
    "        \n",
    "        # Calculate for the second DataFrame\n",
    "        # For total sums, we want to include all payments regardless of alive status\n",
    "        sum_nominal = self.cashflows.sum(axis=(1, 2))\n",
    "        sum_real = self.B_R_i.sum(axis=(1, 2)) if self.B_R_i is not None else None\n",
    "        \n",
    "        mean_sum_nom = np.mean(sum_nominal)\n",
    "        var_sum_nom = np.var(sum_nominal, ddof=1) if len(sum_nominal) > 1 else 0\n",
    "        \n",
    "        if sum_real is not None:\n",
    "            mean_sum_real = np.mean(sum_real)\n",
    "            var_sum_real = np.var(sum_real, ddof=1) if len(sum_real) > 1 else 0\n",
    "        else:\n",
    "            mean_sum_real = None\n",
    "            var_sum_real = None\n",
    "        \n",
    "        value_upfront_total = self.size * self.value_upfront  # Total upfront per simulation\n",
    "        \n",
    "        # Create the second DataFrame\n",
    "        data_df2 = [\n",
    "            [mean_sum_nom, mean_sum_real],\n",
    "            [var_sum_nom, var_sum_real],\n",
    "            [value_upfront_total, value_upfront_total]\n",
    "        ]\n",
    "        df2 = pd.DataFrame(\n",
    "            data_df2,\n",
    "            index=['Mean', 'Variance', 'Value Upfront'],\n",
    "            columns=['Nominal', 'Real']\n",
    "        )\n",
    "        \n",
    "        return df1, df2\n",
    "\n",
    "    def percentiles(self):\n",
    "        \"\"\"\n",
    "        Compute percentiles for various metrics across simulations and return DataFrames in a dictionary.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary of DataFrames containing percentiles for different metrics.\n",
    "                Keys include 'year_income_nominal', 'year_income_nominal_alive',\n",
    "                'year_income_real', 'year_income_real_alive', 'total_cashflow_nominal',\n",
    "                and 'total_cashflow_real'.\n",
    "        \"\"\"\n",
    "        percentiles = np.arange(0, 101, 5)\n",
    "        timeline = self.timeline\n",
    "        ages = [self.start_age + t for t in range(timeline)]\n",
    "        dfs = {}\n",
    "        \n",
    "        # Initialize lists to hold percentile data for each time period\n",
    "        year_income_nominal = []\n",
    "        year_income_nominal_alive = []\n",
    "        year_income_real = []\n",
    "        year_income_real_alive = []\n",
    "        \n",
    "        for t in range(timeline):\n",
    "            # Nominal year income (all members, including dead)\n",
    "            data_nom = self.cashflows[:, :, t].flatten()\n",
    "            perc_nom = np.percentile(data_nom, percentiles)\n",
    "            year_income_nominal.append(perc_nom)\n",
    "            \n",
    "            # Nominal year income given alive (only alive members)\n",
    "            alive_mask = self.alive[:, :, t].flatten().astype(bool)\n",
    "            data_nom_alive = data_nom[alive_mask]\n",
    "            if data_nom_alive.size > 0:\n",
    "                perc_nom_alive = np.percentile(data_nom_alive, percentiles)\n",
    "            else:\n",
    "                perc_nom_alive = np.full(len(percentiles), np.nan)\n",
    "            year_income_nominal_alive.append(perc_nom_alive)\n",
    "            \n",
    "            # Real year income (all members, including dead if real data exists)\n",
    "            if self.B_R_i is not None:\n",
    "                data_real = self.B_R_i[:, :, t].flatten()\n",
    "                perc_real = np.percentile(data_real, percentiles)\n",
    "            else:\n",
    "                perc_real = np.full(len(percentiles), np.nan)\n",
    "            year_income_real.append(perc_real)\n",
    "            \n",
    "            # Real year income given alive (only alive members if real data exists)\n",
    "            if self.B_R_i is not None:\n",
    "                data_real_alive = self.B_R_i[:, :, t].flatten()[alive_mask]\n",
    "                if data_real_alive.size > 0:\n",
    "                    perc_real_alive = np.percentile(data_real_alive, percentiles)\n",
    "                else:\n",
    "                    perc_real_alive = np.full(len(percentiles), np.nan)\n",
    "            else:\n",
    "                perc_real_alive = np.full(len(percentiles), np.nan)\n",
    "            year_income_real_alive.append(perc_real_alive)\n",
    "        \n",
    "        # Create DataFrames for year income metrics\n",
    "        columns = [f'{p}%' for p in percentiles]\n",
    "        index = pd.Index(ages, name='Age')\n",
    "        \n",
    "        dfs['year_income_nominal'] = pd.DataFrame(year_income_nominal, index=index, columns=columns)\n",
    "        dfs['year_income_nominal_alive'] = pd.DataFrame(year_income_nominal_alive, index=index, columns=columns)\n",
    "        dfs['year_income_real'] = pd.DataFrame(year_income_real, index=index, columns=columns) if self.B_R_i is not None else pd.DataFrame()\n",
    "        dfs['year_income_real_alive'] = pd.DataFrame(year_income_real_alive, index=index, columns=columns) if self.B_R_i is not None else pd.DataFrame()\n",
    "        \n",
    "        # Non-time metrics: total cashflows (sum over all time periods)\n",
    "        if self.cashflows is not None:\n",
    "            sum_nominal = self.cashflows.sum(axis=2).flatten()\n",
    "            perc_total_nom = np.percentile(sum_nominal, percentiles)\n",
    "            dfs['total_cashflow_nominal'] = pd.DataFrame([perc_total_nom], columns=columns, index=['Total'])\n",
    "        else:\n",
    "            dfs['total_cashflow_nominal'] = pd.DataFrame()\n",
    "        \n",
    "        if self.B_R_i is not None:\n",
    "            sum_real = self.B_R_i.sum(axis=2).flatten()\n",
    "            perc_total_real = np.percentile(sum_real, percentiles)\n",
    "            dfs['total_cashflow_real'] = pd.DataFrame([perc_total_real], columns=columns, index=['Total'])\n",
    "        else:\n",
    "            dfs['total_cashflow_real'] = pd.DataFrame()\n",
    "        \n",
    "        return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333cb35d",
   "metadata": {},
   "source": [
    "## Life Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0a96ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcono\\AppData\\Local\\Temp\\ipykernel_32904\\1009839751.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table['px'] = 1 - table.loc[: ,'qx']\n"
     ]
    }
   ],
   "source": [
    "life_table = pd.read_excel(wd + \"Data/life_tables.xlsx\")\n",
    "table = life_table[life_table['Year'] == 2022]\n",
    "table['px'] = 1 - table.loc[: ,'qx']\n",
    "true_survival = table.loc[:,['Age', 'px']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64c4a9",
   "metadata": {},
   "source": [
    "## Interest and inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dbab0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interet_rate = pd.read_csv(wd + \"Data/(03-01-25)_Market_interest_rates_(Month).csv\")\n",
    "CPI_table = pd.read_excel(wd + \"Data/CPI_netherlands.xlsx\", sheet_name=\"Monthly\")\n",
    "CPI_yearly = CPI_table.groupby(CPI_table['observation_date'].dt.year, as_index=False).first()\n",
    "interest_rate_Netherlands = interet_rate.loc[(interet_rate[\"sub item\"] == \"10 year\") &\n",
    "                                             (interet_rate[\"region/currency\"] == \"Netherlands\") ][[\"Period\", \"waarde\"]]\n",
    "\n",
    "interest_rate_Netherlands[\"Period\"] = pd.to_datetime(interest_rate_Netherlands[\"Period\"], format=\"%Y-%m\")\n",
    "interest_rate_Netherlands = interest_rate_Netherlands.sort_values(by=\"Period\", ascending=False).reset_index().drop(\"index\", axis =1)\n",
    "annuity = interest_rate_Netherlands.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210b207",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032f2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "from scipy.stats import t\n",
    "from scipy.stats import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fcf9c",
   "metadata": {},
   "source": [
    "### Combined df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4992cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_combined = pd.merge(interest_rate_Netherlands, CPI_table, left_on=\"Period\", right_on=\"observation_date\", how=\"left\")\n",
    "series_combined = series_combined.drop(\"observation_date\", axis=1)\n",
    "series_combined.set_index(\"Period\", inplace=True)\n",
    "series_combined.sort_index(inplace=True)\n",
    "series_combined = series_combined.asfreq('MS')\n",
    "series_combined.rename(columns={\"waarde\": \"InterestRate\", \"NLDCPIALLMINMEI\" : \"CPI\"}, inplace=True)\n",
    "series_combined = series_combined.interpolate(method='linear', limit_direction='both')\n",
    "#series_combined[\"CPI\"] = series_combined[\"CPI\"]/series_combined[\"CPI\"].iloc[0]\n",
    "\n",
    "series_combined[\"CPI\"] = series_combined[\"CPI\"].diff(1)\n",
    "series_combined.fillna(0, inplace=True)\n",
    "series_combinede = series_combined.copy()\n",
    "#series_combined[\"CPI\"] = series_combined[\"CPI\"] * 100\n",
    "series_combined[\"InterestRate\"] = series_combined[\"InterestRate\"].diff(1)\n",
    "series_combined.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9ff2a",
   "metadata": {},
   "source": [
    "#### Forecast parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b81ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_age = 67\n",
    "max_age = 110\n",
    "duration_gsa = max_age - min_age\n",
    "\n",
    "forecast_steps = duration_gsa * 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d51fc",
   "metadata": {},
   "source": [
    "## VECM Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a895b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cointegration Rank: 1\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import VECM, select_coint_rank\n",
    "\n",
    "# Step 1: Test for Cointegration using Johansen Test\n",
    "rank_test = select_coint_rank(\n",
    "    series_combinede, \n",
    "    det_order=-1,  # No deterministic terms\n",
    "    k_ar_diff=12   # Max lag for testing\n",
    ")\n",
    "print(f\"Cointegration Rank: {rank_test.rank}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc5519e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   InterestRate       CPI\n",
      "0      0.068883  0.112042\n",
      "1      0.136027 -0.263986\n",
      "2     -0.118063  0.236357\n",
      "3      0.090628 -0.203470\n",
      "4     -0.147223 -0.426507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Fit VECM\n",
    "rank = rank_test.rank  # Use the detected rank\n",
    "vecm = VECM(\n",
    "    series_combinede,\n",
    "    k_ar_diff=12,         # Lag order\n",
    "    coint_rank=rank,      # Cointegration rank from test\n",
    "    deterministic=\"ci\"    # Include constant in cointegration\n",
    ")\n",
    "vecm_fit = vecm.fit()\n",
    "\n",
    "# Step 3: Extract VECM Residuals\n",
    "residualsv = pd.DataFrame(vecm_fit.resid)\n",
    "\n",
    "\n",
    "residualsv.rename(columns={0:\"InterestRate\", 1:\"CPI\"}, inplace=True)\n",
    "print(residualsv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d72746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcono\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.02087. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Fit GARCH Models on Residuals\n",
    "# CPI Residuals\n",
    "garch_cpi = arch_model(residualsv[\"CPI\"], mean=\"Zero\", vol=\"GARCH\", p=1, q=1, dist=\"t\")\n",
    "garch_cpi_fit = garch_cpi.fit(update_freq=0, disp=\"off\")\n",
    "\n",
    "# Interest Rate Residuals\n",
    "garch_ir = arch_model(residualsv[\"InterestRate\"], mean=\"Zero\", vol=\"GARCH\", p=1, q=1, dist=\"t\")\n",
    "garch_ir_fit = garch_ir.fit(update_freq=0, disp=\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50078988",
   "metadata": {},
   "source": [
    "### VECM engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9474dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastsv = []\n",
    "last_obs = series_combined.values[-vecm_fit.k_ar:]\n",
    "garch_shocks = []\n",
    "\n",
    "for _ in range(forecast_steps):\n",
    "    # 1. VECM Forecast\n",
    "    # Pass None for exog_fc when the model has no exogenous variables\n",
    "    fc = vecm_fit.predict(steps=1, exog_fc=None)\n",
    "    \n",
    "    # 2. Simulate GARCH Shocks\n",
    "    # CPI Shock\n",
    "    cpi_var = garch_cpi_fit.forecast(horizon=1, reindex=False).variance.iloc[-1, 0]\n",
    "    eps_cpi = np.sqrt(cpi_var) * t.rvs(garch_cpi_fit.params[\"nu\"])\n",
    "    \n",
    "    # Interest Rate Shock\n",
    "    ir_var = garch_ir_fit.forecast(horizon=1, reindex=False).variance.iloc[-1, 0]\n",
    "    eps_ir = np.sqrt(ir_var) * t.rvs(garch_ir_fit.params[\"nu\"])\n",
    "    \n",
    "    # Store the shocks\n",
    "    shock_vector = np.array([eps_cpi, eps_ir])\n",
    "    garch_shocks.append(shock_vector)\n",
    "    \n",
    "    # Combine Forecasts and Shocks - ensure proper array handling\n",
    "    # Convert fc to numpy array if it's not already\n",
    "    fc_array = np.array(fc).flatten()  # Ensure it's a flat array\n",
    "    \n",
    "    # Add the shocks to the forecast\n",
    "    full_fc = fc_array + shock_vector\n",
    "    forecastsv.append(full_fc)\n",
    "    \n",
    "    # Update VECM history for next iteration\n",
    "    # Remove oldest observation and add the new forecast\n",
    "    last_obs = np.vstack([last_obs[1:], full_fc.reshape(1, -1)])\n",
    "    \n",
    "    # If VECM model requires updating with new data, do it here\n",
    "    # This might involve re-estimating the model or updating internal state\n",
    "\n",
    "# Convert lists to numpy arrays for easier handling\n",
    "forecasts_array = np.array(forecastsv)\n",
    "garch_shocks_array = np.array(garch_shocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236ca7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_dates = pd.date_range(\n",
    "    start=series_combined.index[-1] + pd.DateOffset(months=1),\n",
    "    periods=forecast_steps,\n",
    "    freq=\"MS\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "796db11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_dfvecm = pd.DataFrame(\n",
    "    np.vstack(forecastsv),\n",
    "    index=forecast_dates,\n",
    "    columns=[ \"CPI_Forecast\", \"InterestRate_Forecast\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b2920",
   "metadata": {},
   "source": [
    "#### Forecast Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04aeb1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_exportvecm = forecast_dfvecm.copy()\n",
    "\n",
    "CPI_0 = 131.480000000000000\n",
    "i_0 = 2.567\n",
    "forecast_exportvecm[\"CPI_Forecast\"] = forecast_exportvecm[\"CPI_Forecast\"].cumsum() + CPI_0\n",
    "#forecast_exportvecm[\"InterestRate_Forecast\"] = forecast_exportvecm[\"InterestRate_Forecast\"].cumsum() + i_0\n",
    "#forecast_exportvecm.to_excel(wd + \"Data/forecastvecm.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40072981",
   "metadata": {},
   "source": [
    "# Test Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b978d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm\n",
    "\n",
    "def rsn(n, mean=0, sd=1, skew=0):\n",
    "    \"\"\"Generate a negatively skewed distribution with specified mean, standard deviation, and skewness.\"\"\"\n",
    "    a = -skew  # Negative `a` creates left skew (right tail is thinner)\n",
    "    delta = a / np.sqrt(1 + a**2)   \n",
    "    loc = mean - sd * delta * np.sqrt(2 / np.pi)\n",
    "    scale = sd * np.sqrt(1 - 2 * delta**2 / np.pi)\n",
    "    return skewnorm.rvs(a, loc=loc, scale=scale, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3930b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSA_TEST = Simulation(size=1000, start_age=min_age, max_age=max_age,\n",
    "                      num_simulations=1000, value_upfront=120_000, seed=42)\n",
    "GSA_TEST.set_survival_probabilities(true_survival)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362dd93",
   "metadata": {},
   "source": [
    "### Liquidity Shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4a97e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026921561040976694\n"
     ]
    }
   ],
   "source": [
    "GSA_TEST.run_mortality_simulation()\n",
    "\n",
    "series_for_simulation = forecast_dfvecm.groupby(forecast_dfvecm.index.year).first()\n",
    "series_for_simulation = series_for_simulation.sort_index(ascending=False).reset_index()\n",
    "\n",
    "inflation_forecast = ((series_for_simulation[\"CPI_Forecast\"].cumsum() + CPI_0)/CPI_0)\n",
    "inflation_forecast = inflation_forecast.values\n",
    "skew_you = rsn(len(series_for_simulation['InterestRate_Forecast']), mean=1, sd=0.5, skew=1.2)\n",
    "return_rate = (series_for_simulation['InterestRate_Forecast'] + skew_you)/100\n",
    "return_rate = return_rate.values \n",
    "\n",
    "inflation_forecast = inflation_forecast[:-2]\n",
    "\n",
    "inflation_forecast = np.insert(inflation_forecast, 0, 1.0)  \n",
    "return_rate = np.insert(return_rate, 0, i_0/100)\n",
    "print(max(return_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74d5c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02367699300699301\n"
     ]
    }
   ],
   "source": [
    "annuity = interest_rate_Netherlands.mean().values[1]/100\n",
    "print(annuity)\n",
    "GSA_TEST.calculate_cashflows_and_portfolio(return_rate[:-2], annuity)\n",
    "GSA_TEST.real_cashflows(inflation_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c954c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_time, results = GSA_TEST.relevant_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e825d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmfs = GSA_TEST.percentiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d87963",
   "metadata": {},
   "source": [
    "# 80/20 Split simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d36fb4",
   "metadata": {},
   "source": [
    "### Stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b781cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = pd.read_csv(wd + \"Data/AEX Historical Data.csv\")\n",
    "stock_data[\"Date\"] = pd.to_datetime(stock_data[\"Date\"])\n",
    "stock_data = stock_data.set_index(\"Date\")\n",
    "stock_data = stock_data.sort_index()\n",
    "stock_data = stock_data[[\"Price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421daf4",
   "metadata": {},
   "source": [
    "## ARIMA GARCH forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b588b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcono\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pcono\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pcono\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   No. Observations:                  287\n",
      "Model:                 ARIMA(0, 2, 1)   Log Likelihood               -1309.469\n",
      "Date:                Sat, 03 May 2025   AIC                           2622.939\n",
      "Time:                        19:07:56   BIC                           2630.244\n",
      "Sample:                    01-01-2001   HQIC                          2625.867\n",
      "                         - 11-01-2024                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ma.L1         -0.9815      0.018    -53.822      0.000      -1.017      -0.946\n",
      "sigma2       566.8199     41.709     13.590      0.000     485.072     648.568\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.03   Jarque-Bera (JB):                30.31\n",
      "Prob(Q):                              0.87   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.00   Skew:                            -0.51\n",
      "Prob(H) (two-sided):                  0.98   Kurtosis:                         4.23\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "                        Constant Mean - GARCH Model Results                         \n",
      "====================================================================================\n",
      "Dep. Variable:                         None   R-squared:                       0.000\n",
      "Mean Model:                   Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                            GARCH   Log-Likelihood:               -1307.44\n",
      "Distribution:      Standardized Student's t   AIC:                           2628.88\n",
      "Method:                  Maximum Likelihood   BIC:                           2654.50\n",
      "                                              No. Observations:                  287\n",
      "Date:                      Sat, May 03 2025   Df Residuals:                      286\n",
      "Time:                              19:07:57   Df Model:                            1\n",
      "                               Mean Model                               \n",
      "========================================================================\n",
      "                 coef    std err          t      P>|t|  95.0% Conf. Int.\n",
      "------------------------------------------------------------------------\n",
      "mu             4.7372      1.124      4.214  2.507e-05 [  2.534,  6.940]\n",
      "                             Volatility Model                             \n",
      "==========================================================================\n",
      "                 coef    std err          t      P>|t|    95.0% Conf. Int.\n",
      "--------------------------------------------------------------------------\n",
      "omega         98.9363     81.075      1.220      0.222 [-59.968,2.578e+02]\n",
      "alpha[1]       0.2088  9.379e-02      2.226  2.601e-02 [2.496e-02,  0.393]\n",
      "alpha[2]       0.0953      0.283      0.337      0.736   [ -0.458,  0.649]\n",
      "beta[1]        0.5297      0.725      0.730      0.465   [ -0.892,  1.951]\n",
      "beta[2]        0.0000      0.407      0.000      1.000   [ -0.797,  0.797]\n",
      "                              Distribution                              \n",
      "========================================================================\n",
      "                 coef    std err          t      P>|t|  95.0% Conf. Int.\n",
      "------------------------------------------------------------------------\n",
      "nu             6.4879      1.955      3.318  9.065e-04 [  2.656, 10.320]\n",
      "========================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcono\\AppData\\Local\\Temp\\ipykernel_32904\\76363812.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  arima_mean = arima_forecast[0]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# 1. Data preparation\n",
    "price_series = stock_data['Price']\n",
    "# Calculate returns (typically used for GARCH modeling)\n",
    "returns = price_series.pct_change().dropna() * 100  # In percentage\n",
    "\n",
    "# 2. Fit ARIMA model to price series\n",
    "# Starting with a simple ARIMA(1,1,1) model - you might need to tune this\n",
    "arima_model = ARIMA(price_series, order=(0, 2, 1))\n",
    "arima_fit = arima_model.fit()\n",
    "print(arima_fit.summary())\n",
    "\n",
    "# 3. Get residuals from ARIMA model for GARCH fitting\n",
    "arima_resid = arima_fit.resid.dropna()\n",
    "\n",
    "# 4. Fit GARCH model to residuals\n",
    "# Using GARCH(1,1) with t-distribution for errors\n",
    "garch_model = arch_model(arima_resid, vol='GARCH', p=2, q=2, dist='t')\n",
    "garch_fit = garch_model.fit(disp='off')\n",
    "print(garch_fit.summary())\n",
    "\n",
    "# 5. Forecast function\n",
    "def forecast_arima_garch(arima_fit, garch_fit, steps=30, last_obs=None):\n",
    "    forecasts = []\n",
    "    forecast_variance = []\n",
    "    \n",
    "    # Get the last observations if not provided\n",
    "    if last_obs is None:\n",
    "        last_obs = price_series.values\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    current_data = np.copy(last_obs)\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        # ARIMA forecast (one step ahead)\n",
    "        arima_forecast = arima_fit.forecast(steps=1)\n",
    "        arima_mean = arima_forecast[0]\n",
    "        \n",
    "        # GARCH forecast (one step ahead variance)\n",
    "        garch_variance = garch_fit.forecast(horizon=1).variance.iloc[-1, 0]\n",
    "        \n",
    "        # Simulate shock from t-distribution\n",
    "        t_shock = t.rvs(garch_fit.params[\"nu\"]) * np.sqrt(garch_variance)\n",
    "        \n",
    "        # Combine ARIMA forecast with GARCH shock\n",
    "        full_forecast = arima_mean + t_shock\n",
    "        \n",
    "        # Store forecasts\n",
    "        forecasts.append(full_forecast)\n",
    "        forecast_variance.append(garch_variance)\n",
    "        \n",
    "        # Update data for next iteration (add new forecast)\n",
    "        current_data = np.append(current_data[1:], full_forecast)\n",
    "        \n",
    "        # Update ARIMA model (optional - can be computationally intensive)\n",
    "        # This would be more accurate but slower:\n",
    "        arima_model = ARIMA(current_data, order=(0,2,1))\n",
    "        arima_fit = arima_model.fit()\n",
    "    \n",
    "    return np.array(forecasts), np.array(forecast_variance)\n",
    "\n",
    "\n",
    "forecasts_ret, forecast_variance_ret = forecast_arima_garch(arima_fit, garch_fit, steps=forecast_steps)\n",
    "\n",
    "# 7. Calculate confidence intervals\n",
    "confidence_level = 0.95\n",
    "t_critical = t.ppf((1 + confidence_level) / 2, garch_fit.params[\"nu\"])\n",
    "lower_bound = forecasts_ret - t_critical * np.sqrt(forecast_variance_ret)\n",
    "upper_bound = forecasts_ret + t_critical * np.sqrt(forecast_variance_ret)\n",
    "\n",
    "# 8. Prepare forecast dates for plotting\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26bf6636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date     Forecast  Lower_Bound  Upper_Bound    Variance\n",
      "0   2024-12-01   904.234631   840.903911   967.565352  694.585509\n",
      "1   2025-01-01   905.812740   842.482019   969.143460  694.585509\n",
      "2   2025-02-01   918.787465   855.456744   982.118185  694.585509\n",
      "3   2025-03-01   873.078700   809.747980   936.409421  694.585509\n",
      "4   2025-04-01   879.245932   815.915211   942.576652  694.585509\n",
      "..         ...          ...          ...          ...         ...\n",
      "511 2067-07-01  2431.380951  2368.050230  2494.711672  694.585509\n",
      "512 2067-08-01  2389.665629  2326.334909  2452.996350  694.585509\n",
      "513 2067-09-01  2363.300150  2299.969430  2426.630871  694.585509\n",
      "514 2067-10-01  2399.357132  2336.026411  2462.687853  694.585509\n",
      "515 2067-11-01  2336.326163  2272.995443  2399.656884  694.585509\n",
      "\n",
      "[516 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 10. Print forecast results\n",
    "forecast_df_ret = pd.DataFrame({\n",
    "    'Date': forecast_dates,\n",
    "    'Forecast': forecasts_ret,\n",
    "    'Lower_Bound': lower_bound,\n",
    "    'Upper_Bound': upper_bound,\n",
    "    'Variance': forecast_variance_ret\n",
    "})\n",
    "print(forecast_df_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5fd84ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2024         NaN\n",
      "2025    0.001745\n",
      "2026   -0.050164\n",
      "2027    0.159815\n",
      "2028    0.143155\n",
      "2029    0.189826\n",
      "2030    0.038490\n",
      "2031   -0.023553\n",
      "2032   -0.028226\n",
      "2033    0.105562\n",
      "2034    0.044070\n",
      "2035    0.094364\n",
      "2036    0.082034\n",
      "2037    0.031966\n",
      "2038   -0.029194\n",
      "2039    0.089028\n",
      "2040    0.027484\n",
      "2041   -0.037560\n",
      "2042   -0.031110\n",
      "2043   -0.008803\n",
      "2044   -0.010990\n",
      "2045   -0.048943\n",
      "2046    0.025054\n",
      "2047   -0.005835\n",
      "2048    0.078002\n",
      "2049    0.024523\n",
      "2050    0.061980\n",
      "2051    0.078828\n",
      "2052    0.037302\n",
      "2053    0.091119\n",
      "2054   -0.063230\n",
      "2055   -0.026843\n",
      "2056    0.001110\n",
      "2057    0.044558\n",
      "2058   -0.002610\n",
      "2059    0.048469\n",
      "2060   -0.067060\n",
      "2061    0.034122\n",
      "2062   -0.045727\n",
      "2063    0.039938\n",
      "2064   -0.033761\n",
      "2065   -0.006919\n",
      "2066    0.018835\n",
      "2067    0.032565\n",
      "Name: Forecast, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly_return = forecast_df_ret.groupby(forecast_df_ret['Date'].dt.year)['Forecast'].first().pct_change() \n",
    "print(yearly_return)\n",
    "yearly_return = yearly_return.values\n",
    "yearly_return[0] = 0\n",
    "len(yearly_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b07ea1",
   "metadata": {},
   "source": [
    "## GSA with investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9946ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_weights = (0.8, 0.2)\n",
    "GSA_I = Simulation(size=2000, start_age=min_age, max_age=max_age,\n",
    "                      num_simulations=2000, value_upfront=120_000, seed=42)\n",
    "GSA_I.set_survival_probabilities(true_survival)\n",
    "GSA_I.run_mortality_simulation()\n",
    "ret_withi = return_rate[:-2] * investment_weights[0] + yearly_return[:-1] * investment_weights[1]\n",
    "GSA_I.calculate_cashflows_and_portfolio(ret_withi, annuity)\n",
    "GSA_I.real_cashflows(inflation_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04c9d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_timei, resultsi = GSA_I.relevant_metrics()\n",
    "percentilesi = GSA_I.percentiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "076367e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(84.862775), np.float64(29.270425), np.float64(7.488849999999999))\n"
     ]
    }
   ],
   "source": [
    "GSA_I.set_stability_tolerances(0.1, 1, 0.2, 2, 0.05, 0.05)\n",
    "print(GSA_I.check_stability(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a9503",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentilesi['year_income_nominal_alive'].to_excel(wd + \"Data/percentiles_investment.xlsx\")\n",
    "percentilesi['year_income_real_alive'].to_excel(wd + \"Data/percentiles_investment_real.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentilesi['total_cashflow_nominal'].to_excel(wd + \"Data/total_percentiles_nominal.xlsx\")\n",
    "percentilesi['total_cashflow_real'].to_excel(wd + \"Data/total_percentiles_real.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e00143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_timei.to_excel(wd + \"Data/second_batch_ofresults.xlsx\")\n",
    "resultsi.to_excel(wd + \"Data/totals_second_batch_ofresults.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c070e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabilities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3fd9521",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m GSAn\u001b[38;5;241m.\u001b[39mset_survival_probabilities(true_survival)\n\u001b[0;32m      5\u001b[0m GSAn\u001b[38;5;241m.\u001b[39mrun_mortality_simulation()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mGSAn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_cashflows_and_portfolio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_withi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannuity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m GSAn\u001b[38;5;241m.\u001b[39mreal_cashflows(inflation_forecast)\n\u001b[0;32m      8\u001b[0m GSAn\u001b[38;5;241m.\u001b[39mset_stability_tolerances(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.05\u001b[39m)\n",
      "Cell \u001b[1;32mIn[40], line 142\u001b[0m, in \u001b[0;36mSimulation.calculate_cashflows_and_portfolio\u001b[1;34m(self, interest_rates, annuity_discount)\u001b[0m\n\u001b[0;32m    139\u001b[0m current_portfolio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_N_i[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t]\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Ensure positive portfolio values (avoid negative balances)\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m current_portfolio \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_portfolio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Calculate cashflows B_i(t) using equation (7)\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# B_i(t) = I{T_i > t} * v_N_i(t) / ä_x+t\u001b[39;00m\n\u001b[0;32m    146\u001b[0m B_t \u001b[38;5;241m=\u001b[39m (current_portfolio \u001b[38;5;241m/\u001b[39m annuity_factors[t]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malive[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [6000, 7000, 8000, 9000, 10000]:\n",
    "    GSAn = Simulation(size=i, start_age=min_age, max_age=max_age,\n",
    "                      num_simulations=1000, value_upfront=120_000, seed=42)\n",
    "    GSAn.set_survival_probabilities(true_survival)\n",
    "    GSAn.run_mortality_simulation()\n",
    "    GSAn.calculate_cashflows_and_portfolio(ret_withi, annuity)\n",
    "    GSAn.real_cashflows(inflation_forecast)\n",
    "    GSAn.set_stability_tolerances(0.1, 1, 0.2, 2, 0.05, 0.05)\n",
    "    stabilities[f\"{i}\"] = GSAn.check_stability(90)\n",
    "    del GSAn\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56f719ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1000': (np.float64(81.8637), np.float64(29.3287), np.float64(7.7527)), '2000': (np.float64(84.64735), np.float64(29.318699999999996), np.float64(7.4712)), '3000': (np.float64(86.575), np.float64(29.489666666666665), np.float64(7.493266666666666)), '4000': (np.float64(86.971575), np.float64(29.478749999999998), np.float64(7.22655)), '5000': (np.float64(88.26458000000001), np.float64(29.547240000000002), np.float64(7.102060000000001))}\n"
     ]
    }
   ],
   "source": [
    "print(stabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
